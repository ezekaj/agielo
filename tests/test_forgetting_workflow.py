"""
Tests for Complete Forgetting Workflow
======================================

Integration tests for the complete memory forgetting + spaced repetition workflow:
1. Episode creation in EpisodicMemoryStore
2. Registration with EbbinghausForgetting system
3. Retention decay over time
4. Spaced repetition scheduling
5. Review and reinforcement
6. Memory consolidation and forgetting

This tests the full lifecycle of episodic memories through the forgetting system.
"""

import unittest
import tempfile
import os
import time
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import pytest

import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from neuro_memory.memory.episodic_store import (
    EpisodicMemoryStore,
    EpisodicMemoryConfig,
    Episode
)
from neuro_memory.memory.forgetting import (
    EbbinghausForgetting,
    EbbinghausConfig,
    SpacedRepetitionScheduler,
    SpacedRepetitionConfig,
    ForgettingEngine,
    ForgettingConfig
)


class TestEpisodeCreationToRegistration(unittest.TestCase):
    """Test workflow from episode creation to Ebbinghaus registration."""

    def setUp(self):
        """Set up a fresh memory store for each test."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=100,
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True,
            enable_disk_offload=True
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_episode_registered_with_ebbinghaus_on_creation(self):
        """Test that storing an episode registers it with Ebbinghaus forgetting."""
        content = np.random.randn(10)
        episode = self.memory.store_episode(
            content=content,
            surprise=1.5,
            location="test_location"
        )

        # Episode should be registered with Ebbinghaus
        self.assertIsNotNone(self.memory.ebbinghaus)
        state = self.memory.ebbinghaus.get_memory_state(episode.episode_id)
        self.assertIsNotNone(state, "Episode should be registered with Ebbinghaus")
        self.assertEqual(state.memory_id, episode.episode_id)

    def test_episode_scheduled_for_spaced_repetition(self):
        """Test that storing an episode schedules it for spaced repetition review."""
        content = np.random.randn(10)
        episode = self.memory.store_episode(
            content=content,
            surprise=2.0
        )

        # Episode should be scheduled for review
        self.assertIsNotNone(self.memory.spaced_repetition)
        review_item = self.memory.spaced_repetition.get_review_item(episode.episode_id)
        self.assertIsNotNone(review_item, "Episode should be scheduled for review")
        self.assertEqual(review_item.interval_level, 0)
        self.assertFalse(review_item.is_immediate)

    def test_initial_retention_based_on_importance(self):
        """Test that initial retention is scaled by episode importance."""
        # High surprise -> high importance -> higher initial retention
        high_surprise_episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=5.0  # Very surprising
        )

        # Lower surprise -> lower importance
        low_surprise_episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=0.1  # Not surprising
        )

        high_state = self.memory.ebbinghaus.get_memory_state(high_surprise_episode.episode_id)
        low_state = self.memory.ebbinghaus.get_memory_state(low_surprise_episode.episode_id)

        # High surprise should have higher initial retention
        self.assertGreater(high_state.initial_retention, low_state.initial_retention)

    def test_multiple_episodes_all_registered(self):
        """Test that multiple episodes are all independently registered."""
        episodes = []
        for i in range(5):
            ep = self.memory.store_episode(
                content=np.random.randn(10),
                surprise=float(i),
                location=f"loc_{i}"
            )
            episodes.append(ep)

        # All should be registered
        for ep in episodes:
            state = self.memory.ebbinghaus.get_memory_state(ep.episode_id)
            self.assertIsNotNone(state, f"Episode {ep.episode_id} should be registered")


class TestRetentionDecayOverTime(unittest.TestCase):
    """Test workflow of memory retention decay over simulated time."""

    def setUp(self):
        """Set up a fresh memory store for each test."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=100,
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True,
            review_threshold=0.3
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_retention_starts_near_initial_retention(self):
        """Test that retention equals initial_retention immediately after creation.

        Note: Initial retention is scaled by importance in EpisodicMemoryStore:
        initial_retention = BASE + (FACTOR * importance)
        So retention won't be exactly 1.0 but should match the computed initial_retention.
        """
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0
        )

        now = datetime.now().timestamp()
        state = self.memory.ebbinghaus.get_memory_state(episode.episode_id)
        retention = self.memory.ebbinghaus.compute_retention(
            episode.episode_id,
            current_time=now
        )

        # Retention should be close to initial_retention (not 1.0)
        # At time=0, R = e^(-0/S) * initial_retention = initial_retention
        self.assertAlmostEqual(retention, state.initial_retention, delta=0.05)

    def test_retention_decreases_over_time(self):
        """Test that retention decreases following Ebbinghaus curve R = e^(-t/S)."""
        base_time = datetime.now().timestamp()
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0
        )

        retentions = []
        for hours in [0, 1, 2, 4, 8]:
            current_time = base_time + hours * 3600
            retention = self.memory.ebbinghaus.compute_retention(
                episode.episode_id,
                current_time=current_time
            )
            retentions.append(retention)

        # Retention should be monotonically decreasing
        for i in range(1, len(retentions)):
            self.assertLess(
                retentions[i], retentions[i-1],
                f"Retention at hour {[0,1,2,4,8][i]} should be less than previous"
            )

    def test_should_forget_when_retention_drops_below_threshold(self):
        """Test that memories are marked for forgetting when retention drops."""
        # Use custom config with known stability for predictable decay
        ebbinghaus_config = EbbinghausConfig(
            base_stability=1.0,  # 1 hour stability
            forget_threshold=0.3
        )

        # Create standalone Ebbinghaus for controlled test
        ebbinghaus = EbbinghausForgetting(config=ebbinghaus_config)
        base_time = 1000000.0

        ebbinghaus.register_memory("test_mem", timestamp=base_time)

        # After 2 hours with S=1, R = e^(-2) â‰ˆ 0.135 < 0.3
        two_hours_later = base_time + 2 * 3600
        should_forget = ebbinghaus.should_forget("test_mem", current_time=two_hours_later)

        self.assertTrue(should_forget, "Memory should be marked for forgetting")

    def test_memories_at_risk_tracking(self):
        """Test that memories below threshold are tracked as at-risk."""
        ebbinghaus = EbbinghausForgetting(config=EbbinghausConfig(
            base_stability=1.0,
            forget_threshold=0.5
        ))
        base_time = 1000000.0

        # Fresh memory
        ebbinghaus.register_memory("fresh", timestamp=base_time)

        # Old memory (2 hours old)
        ebbinghaus.register_memory("old", timestamp=base_time - 2 * 3600)

        at_risk = ebbinghaus.get_memories_below_threshold(current_time=base_time)

        # Old memory should be at risk
        at_risk_ids = [mem_id for mem_id, _ in at_risk]
        self.assertIn("old", at_risk_ids)
        self.assertNotIn("fresh", at_risk_ids)


class TestSpacedRepetitionReviewWorkflow(unittest.TestCase):
    """Test the spaced repetition review workflow."""

    def setUp(self):
        """Set up memory store and spaced repetition scheduler."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=100,
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_record_retrieval_updates_ebbinghaus(self):
        """Test that recording a retrieval updates the Ebbinghaus system."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0
        )

        initial_stability = self.memory.ebbinghaus.get_memory_state(
            episode.episode_id
        ).stability_score

        # Record successful retrieval
        self.memory.record_retrieval(episode.episode_id, success=True)

        new_stability = self.memory.ebbinghaus.get_memory_state(
            episode.episode_id
        ).stability_score

        # Stability should increase
        self.assertGreater(new_stability, initial_stability)

    def test_record_retrieval_updates_spaced_repetition(self):
        """Test that recording a retrieval updates the spaced repetition schedule."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0
        )

        initial_level = self.memory.spaced_repetition.get_review_item(
            episode.episode_id
        ).interval_level

        # Record successful retrieval
        self.memory.record_retrieval(episode.episode_id, success=True)

        new_level = self.memory.spaced_repetition.get_review_item(
            episode.episode_id
        ).interval_level

        # Interval level should increase
        self.assertGreater(new_level, initial_level)

    def test_failed_retrieval_schedules_immediate_review(self):
        """Test that failed retrieval schedules immediate review."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0
        )

        # Build up some level
        self.memory.record_retrieval(episode.episode_id, success=True)
        self.memory.record_retrieval(episode.episode_id, success=True)

        # Fail
        self.memory.record_retrieval(episode.episode_id, success=False)

        review_item = self.memory.spaced_repetition.get_review_item(episode.episode_id)

        self.assertTrue(review_item.is_immediate)
        self.assertEqual(review_item.interval_level, 0)

    def test_multiple_retrievals_strengthen_memory(self):
        """Test that multiple successful retrievals strengthen memory."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0
        )

        initial_stability = self.memory.ebbinghaus.get_memory_state(
            episode.episode_id
        ).stability_score

        # Multiple successful retrievals
        for _ in range(5):
            self.memory.record_retrieval(episode.episode_id, success=True)

        final_stability = self.memory.ebbinghaus.get_memory_state(
            episode.episode_id
        ).stability_score

        # Stability should have increased significantly
        self.assertGreater(final_stability, initial_stability * 3)

    def test_get_memories_for_review_returns_due_episodes(self):
        """Test getting memories that are due for review."""
        # Use custom scheduler with short intervals for testing
        config = SpacedRepetitionConfig(base_intervals=[0.0001])  # Very short
        ebbinghaus = EbbinghausForgetting(config=EbbinghausConfig(base_stability=0.0001))
        scheduler = SpacedRepetitionScheduler(ebbinghaus=ebbinghaus, config=config)

        # Schedule some memories
        now = datetime.now().timestamp()
        scheduler.schedule_memory("mem_1", current_time=now)
        scheduler.schedule_memory("mem_2", current_time=now)

        # Slight delay to let them become due
        time.sleep(0.01)

        due = scheduler.get_due_for_review(limit=10)
        self.assertEqual(len(due), 2)


class TestMemoryReinforcementWorkflow(unittest.TestCase):
    """Test the memory reinforcement workflow for high-value memories."""

    def setUp(self):
        """Set up memory store with auto-reinforcement enabled."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=100,
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True,
            auto_reinforce_high_value=True
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_high_importance_memory_should_be_reinforced(self):
        """Test that high importance memory is flagged for reinforcement."""
        # Create high-surprise (high-importance) episode
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=10.0  # Very high surprise -> high importance
        )

        should_reinforce = self.memory._should_reinforce_memory(episode)
        self.assertTrue(should_reinforce)

    def test_low_importance_memory_should_not_be_reinforced(self):
        """Test that low importance memory is not flagged for reinforcement."""
        # Create low-surprise (low-importance) episode
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=0.01  # Very low surprise -> low importance
        )

        # Clear entities to ensure it's truly low-value
        episode.entities = []
        episode.metadata = {}

        should_reinforce = self.memory._should_reinforce_memory(episode)
        self.assertFalse(should_reinforce)

    def test_memory_with_many_entities_reinforced(self):
        """Test that memory linked to many entities is reinforced."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=0.1,  # Low surprise
            entities=["person_1", "person_2", "person_3", "person_4"]  # Many entities
        )

        should_reinforce = self.memory._should_reinforce_memory(episode)
        self.assertTrue(should_reinforce)

    def test_frequently_accessed_memory_reinforced(self):
        """Test that frequently accessed memory is reinforced."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=0.1,  # Low surprise
            metadata={'access_count': 10}  # Frequently accessed
        )

        should_reinforce = self.memory._should_reinforce_memory(episode)
        self.assertTrue(should_reinforce)


class TestForgettingProcessWorkflow(unittest.TestCase):
    """Test the complete forgetting process workflow."""

    def setUp(self):
        """Set up memory store for forgetting tests."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=100,
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True,
            enable_disk_offload=True,
            auto_reinforce_high_value=False  # Disable for predictable tests
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_forgetting_statistics_tracked(self):
        """Test that forgetting statistics are tracked."""
        # Store some episodes
        for i in range(5):
            self.memory.store_episode(
                content=np.random.randn(10),
                surprise=float(i)
            )

        stats = self.memory.get_forgetting_statistics()

        self.assertIn("forgotten_memories", stats)
        self.assertIn("reviewed_memories", stats)
        self.assertIn("reinforced_memories", stats)
        self.assertIn("ebbinghaus", stats)
        self.assertIn("spaced_repetition", stats)

    def test_forgetting_cleans_up_indices(self):
        """Test that forgetting removes episode from all indices."""
        # Store episode with location and entities
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0,
            location="test_location",
            entities=["entity_1", "entity_2"]
        )

        # Verify it's in indices
        self.assertIn(episode.episode_id, self.memory.spatial_index.get("test_location", []))
        self.assertIn(episode.episode_id, self.memory.entity_index.get("entity_1", []))

        # Manually remove from indices using internal method
        self.memory._remove_from_indices(episode)

        # Should be removed from indices
        self.assertNotIn(episode.episode_id, self.memory.spatial_index.get("test_location", []))
        self.assertNotIn(episode.episode_id, self.memory.entity_index.get("entity_1", []))


class TestConsolidationWorkflow(unittest.TestCase):
    """Test the memory consolidation workflow."""

    def setUp(self):
        """Set up memory store with low thresholds for testing."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=10,  # Low for testing
            offload_threshold=8,  # Trigger consolidation early
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True,
            enable_disk_offload=True
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_consolidation_triggered_at_threshold(self):
        """Test that consolidation is triggered when threshold reached."""
        # Store more than offload_threshold episodes
        for i in range(12):
            self.memory.store_episode(
                content=np.random.randn(10),
                surprise=float(i % 3)  # Variable surprise
            )

        # Some should have been offloaded
        self.assertGreater(self.memory.episodes_offloaded, 0)

    def test_high_importance_episodes_kept_in_memory(self):
        """Test that high importance episodes are kept during consolidation."""
        # Store low importance episodes first
        for i in range(6):
            self.memory.store_episode(
                content=np.random.randn(10),
                surprise=0.1  # Low surprise
            )

        # Store high importance episode
        high_importance_ep = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=10.0  # Very high surprise
        )

        # Store more low importance to trigger consolidation
        for i in range(6):
            self.memory.store_episode(
                content=np.random.randn(10),
                surprise=0.1
            )

        # High importance episode should still be retrievable from memory
        found = self.memory._get_episode_by_id(high_importance_ep.episode_id)
        self.assertIsNotNone(found)

    def test_offloaded_episodes_saved_to_disk(self):
        """Test that offloaded episodes are saved to disk."""
        # Store many episodes to trigger consolidation
        for i in range(15):
            self.memory.store_episode(
                content=np.random.randn(10),
                surprise=0.1
            )

        # Check offload directory exists and has files
        offload_dir = Path(self.temp_dir) / "offloaded"
        if offload_dir.exists():
            offloaded_files = list(offload_dir.glob("*.pkl"))
            self.assertGreater(len(offloaded_files), 0)


class TestFullWorkflowIntegration(unittest.TestCase):
    """Integration test for the full forgetting workflow."""

    def setUp(self):
        """Set up memory store for full integration test."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=50,
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True,
            enable_disk_offload=True,
            auto_reinforce_high_value=True
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_complete_memory_lifecycle(self):
        """
        Test complete memory lifecycle:
        1. Create episode
        2. Register with forgetting system
        3. Retrieve and strengthen
        4. Check retention
        5. Verify statistics
        """
        # 1. Create episode
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=2.0,
            location="office",
            entities=["colleague", "project"]
        )

        # 2. Verify registration
        ebbinghaus_state = self.memory.ebbinghaus.get_memory_state(episode.episode_id)
        self.assertIsNotNone(ebbinghaus_state)

        review_item = self.memory.spaced_repetition.get_review_item(episode.episode_id)
        self.assertIsNotNone(review_item)

        initial_stability = ebbinghaus_state.stability_score

        # 3. Simulate multiple retrievals (strengthening)
        for _ in range(3):
            self.memory.record_retrieval(episode.episode_id, success=True)

        # 4. Verify retention improved
        new_state = self.memory.ebbinghaus.get_memory_state(episode.episode_id)
        self.assertGreater(new_state.stability_score, initial_stability)
        # Note: access_count is 6 because record_retrieval() on EpisodicMemoryStore
        # calls both ebbinghaus.record_retrieval() AND spaced_repetition.record_review()
        # and record_review() internally also calls ebbinghaus.record_retrieval()
        # So each call to memory.record_retrieval() results in 2 access_count increments
        self.assertEqual(new_state.access_count, 6)  # 3 retrievals * 2 = 6

        # 5. Check statistics
        stats = self.memory.get_statistics()
        self.assertEqual(stats["total_episodes"], 1)
        self.assertEqual(stats["reviewed_memories"], 3)

        forgetting_stats = self.memory.get_forgetting_statistics()
        self.assertIn("ebbinghaus", forgetting_stats)
        self.assertIn("spaced_repetition", forgetting_stats)

    def test_mixed_importance_memories_over_time(self):
        """
        Test workflow with mixed importance memories:
        - High importance should have higher retention
        - Low importance should decay faster
        """
        # Create high and low importance memories
        high_imp = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=8.0  # High
        )

        low_imp = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=0.1  # Low
        )

        # High importance should have higher initial retention
        high_state = self.memory.ebbinghaus.get_memory_state(high_imp.episode_id)
        low_state = self.memory.ebbinghaus.get_memory_state(low_imp.episode_id)

        self.assertGreater(high_state.initial_retention, low_state.initial_retention)

        # Verify both are scheduled for review
        high_review = self.memory.spaced_repetition.get_review_item(high_imp.episode_id)
        low_review = self.memory.spaced_repetition.get_review_item(low_imp.episode_id)

        self.assertIsNotNone(high_review)
        self.assertIsNotNone(low_review)

    def test_persistence_across_sessions(self):
        """Test that forgetting state persists across sessions."""
        # Create and strengthen an episode
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.5
        )

        for _ in range(3):
            self.memory.record_retrieval(episode.episode_id, success=True)

        # Get state before save
        stability_before = self.memory.ebbinghaus.get_memory_state(
            episode.episode_id
        ).stability_score

        # Save and cleanup
        self.memory.save_state()
        if self.memory.ebbinghaus:
            self.memory.ebbinghaus._save_state()
        if self.memory.spaced_repetition:
            self.memory.spaced_repetition._save_state()

        # Create new memory store with same path
        memory2 = EpisodicMemoryStore(self.config)
        memory2.load_state()

        # Verify episode preserved
        retrieved = memory2._get_episode_by_id(episode.episode_id)
        self.assertIsNotNone(retrieved)

        # Verify Ebbinghaus state preserved
        state2 = memory2.ebbinghaus.get_memory_state(episode.episode_id)
        if state2:  # May need to re-register after load
            self.assertAlmostEqual(state2.stability_score, stability_before, delta=0.1)

        memory2.cleanup()


class TestForgettingEngineWorkflow(unittest.TestCase):
    """Test the legacy ForgettingEngine workflow."""

    def test_activation_decay_workflow(self):
        """Test complete activation decay workflow with ForgettingEngine."""
        engine = ForgettingEngine(ForgettingConfig(
            decay_rate=0.5,
            rehearsal_boost=1.5,
            min_activation=0.1
        ))

        initial_activation = 2.0
        timestamp = datetime.now() - timedelta(hours=12)

        # Compute activation after 12 hours
        activation_no_rehearsal = engine.compute_activation(
            initial_activation, timestamp, rehearsal_count=0
        )

        # Same time but with rehearsals
        activation_with_rehearsal = engine.compute_activation(
            initial_activation, timestamp, rehearsal_count=3
        )

        # Rehearsal should boost activation
        self.assertGreater(activation_with_rehearsal, activation_no_rehearsal)

    def test_forgetting_probability_workflow(self):
        """Test forgetting probability calculation workflow."""
        engine = ForgettingEngine()

        # High activation -> low forgetting probability
        high_prob = engine.get_forgetting_probability(1.0)
        # Low activation -> high forgetting probability
        low_prob = engine.get_forgetting_probability(0.01)

        self.assertLess(high_prob, low_prob)
        self.assertLessEqual(high_prob, 0.5)
        self.assertGreaterEqual(low_prob, 0.5)


class TestEdgeCasesAndErrorHandling(unittest.TestCase):
    """Test edge cases and error handling in the forgetting workflow."""

    def setUp(self):
        """Set up memory store for edge case tests."""
        self.temp_dir = tempfile.mkdtemp()
        self.config = EpisodicMemoryConfig(
            max_episodes=100,
            embedding_dim=64,
            persistence_path=self.temp_dir,
            enable_ebbinghaus=True
        )
        self.memory = EpisodicMemoryStore(self.config)

    def tearDown(self):
        """Clean up temp directory."""
        import shutil
        try:
            self.memory.cleanup()
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except Exception:
            pass

    def test_retrieval_of_nonexistent_episode(self):
        """Test that recording retrieval for nonexistent episode is handled."""
        # Should not raise - just do nothing
        self.memory.record_retrieval("nonexistent_episode", success=True)

        # Stats should still work
        stats = self.memory.get_statistics()
        self.assertIsNotNone(stats)

    def test_zero_surprise_episode(self):
        """Test creating episode with zero surprise."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=0.0
        )

        self.assertIsNotNone(episode)
        state = self.memory.ebbinghaus.get_memory_state(episode.episode_id)
        self.assertIsNotNone(state)

    def test_very_high_surprise_episode(self):
        """Test creating episode with very high surprise."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=100.0  # Extremely high
        )

        self.assertIsNotNone(episode)
        # Importance should be capped at 1.0
        self.assertLessEqual(episode.importance, 1.0)

    def test_empty_entities_and_location(self):
        """Test creating episode with no entities or location."""
        episode = self.memory.store_episode(
            content=np.random.randn(10),
            surprise=1.0,
            entities=[],
            location=None
        )

        self.assertIsNotNone(episode)
        state = self.memory.ebbinghaus.get_memory_state(episode.episode_id)
        self.assertIsNotNone(state)

    def test_statistics_with_no_episodes(self):
        """Test getting statistics when no episodes exist."""
        stats = self.memory.get_statistics()

        self.assertEqual(stats["total_episodes"], 0)
        self.assertEqual(stats["episodes_in_memory"], 0)

    def test_forgetting_statistics_with_no_episodes(self):
        """Test getting forgetting statistics when no episodes exist."""
        stats = self.memory.get_forgetting_statistics()

        self.assertEqual(stats["forgotten_memories"], 0)
        self.assertEqual(stats["reviewed_memories"], 0)


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
